from cgitb import enable
from dython.nominal import associations
from pydoc import Helper
import sched
from sklearn.tree import DecisionTreeRegressor
from random import random
from tabnanny import verbose
import numpy as np
import pandas as pd
from scipy import stats
from sklearn.model_selection import train_test_split, KFold, GridSearchCV, TimeSeriesSplit
import sklearn.preprocessing as preproc
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import ElasticNet
from sklearn.neighbors import KNeighborsRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from importlib.resources import path
import Helpers.ErrorMetrics
import Helpers.DataPreprocessing as hdp
import Helpers.SamplingPreprocessing as spreproc
import Helpers.DataPreprocessing2

import os
import sys
script_path = os.path.abspath('')
sys.path.append(script_path)
sys.path.append(os.path.join(script_path, 'Helpers'))

sns.set()


# Read data
file_name = 'Realized Schedule 20210101-20220228.xlsx'
raw_data = pd.read_excel(file_name)

# Transform AircraftType in only strings
raw_data.loc[:, ('AircraftType')] = raw_data.loc[:,
                                                 ('AircraftType')].astype(str)


dataset = raw_data.loc[raw_data.LoadFactor > 0]
dataset = dataset.sort_values(by='ScheduleTime')
throw_away_due_to_covid = len(dataset.loc[(
    raw_data.ScheduleTime.dt.year == 2021) & (raw_data.ScheduleTime.dt.month < 5)].index)

dataset = dataset[throw_away_due_to_covid:]
dataset.drop(['FlightNumber',  'Sector'], axis=1, inplace=True)

# training_length = int(2/3*dataset.shape[0])
# train_dataset = dataset[0:training_length]
# test_dataset = dataset[training_length:]
# test_dataset2 = dataset[training_length:].sort_values(by='ScheduleTime')
# y_test = test_dataset[["LoadFactor"]]
# X_test = test_dataset.drop(['LoadFactor'], axis=1)


# trnsf = spreproc.SamplingTransformer(sample_by='hours')
# X, idx, y = trnsf.fit(train_dataset)

# X2, idx2, y2 = trnsf.fit(test_dataset)

#X3, idx3, _ = trnsf.fit(test_dataset[-300:])

#schedule = trnsf.from_sampled_to_schedule_format(y2[-len(idx3):], X_test[-300:])


transformer = Helpers.DataPreprocessing2.DataTransformer(
    top_percent=80, dummy_encode=True)
transformer.fit(dataset)
data = transformer.transform(dataset)
#data.drop(['Year'], axis=1, inplace=True)
data2, enc_map2 = transformer.target_encode_column_df(
    data, "LoadFactor", 'Destination')

#associations(data2)

data2.corr()
data2.drop(['Month', 'Day', 'Year'], axis = 1, inplace=True)



X_df = data2.drop(['LoadFactor'], axis=1)
y_df = data2['LoadFactor']

X = X_df.values
y = y_df.values.ravel()

n, p = X.shape


def deviance(lf_act, lf_hat):
    # We want deviance close to 0
    return np.abs((lf_hat-lf_act)/lf_act)


n_estimators = range(10, 101, 10)
max_depth = range(1, 11)
max_features = range(8, 15, 1)

param_grid = {
    # 'n_estimators': n_estimators,
    'max_depth': max_depth,
    'max_features': max_features
}

regr = GridSearchCV(RandomForestRegressor(
    bootstrap=True, n_jobs=-1), param_grid=param_grid, n_jobs=-1, verbose=2)

regr.fit(X, y)

df = pd.DataFrame(regr.cv_results_)
df.to_csv('ResultsRandomForest.csv')

importance_dictionary = dict(
    zip(np.asarray(X_df.columns), regr.best_estimator_.feature_importances_))
importance_dictionary = dict(
    sorted(importance_dictionary.items(), key=lambda x: x[1], reverse=True))


# years = np.asarray(data.Year.unique())
# mean_no_of_pas = []
# for i, year in enumerate(years):
#     df_year = data.loc[data.Year==year]
#     months = np.asarray(df_year.Month)
#     month_pass = []
#     for month in months:
#         df_month = df_year.loc[df_year.Month==month]
#         lf = np.asarray(df_month.LoadFactor)
#         seat_cap = np.asarray(df_month.SeatCapacity)
#         num_of_pas = np.mean(lf*seat_cap)
#         month_pass.append(num_of_pas)
#     plt.plot(np.array(months)+i*12,np.array(month_pass), 'x-', label=year )

# plt.xlabel('Months')
# plt.ylabel('Mean number of passengers')
# plt.legend()

# plt.savefig('MonthlyMeanNumberOfPassengers.pdf')
# plt.show()


# years = np.asarray(data.Year.unique())
# mean_no_of_pas = []
# for i, year in enumerate(years):
#     df_year = data.loc[data.Year==year]
#     months = np.asarray(df_year.Month)
#     month_num_of_flights = []
#     for month in months:
#         df_month = df_year.loc[df_year.Month==month]
#         lf = len(np.asarray(df_month.LoadFactor))
#         month_num_of_flights.append(lf)
#     plt.plot(np.array(months)+i*12,np.array(month_num_of_flights), 'x-', label=year )

# plt.xlabel('Months')
# plt.ylabel('Number of flights')
# plt.legend()

# plt.savefig('MonthlyNumberOfFlights.pdf')
# plt.show()

# plt.figure(figsize=(15,10))
# years = np.asarray(data.Year.unique())
# period_index = len(dataset.loc[(
#     raw_data.ScheduleTime.dt.year == 2021) & (raw_data.ScheduleTime.dt.month < 5)].index)
# for i, year in enumerate(years):
#     if i == 0:
#         period_df = data[:period_index]
#         period_str = 'Before May 2021'
#     else:
#         period_df = data[period_index:]
#         period_str = 'After May 2021'
#     unique_aircraft_types = np.asarray(period_df.AircraftType.unique())
#     mean_per_air = []
#     for aircraft in unique_aircraft_types:
#         aircraft_df = period_df.loc[period_df.AircraftType==aircraft]
#         lf = np.asarray(aircraft_df.LoadFactor)
#         seat_cap = np.asarray(aircraft_df.SeatCapacity)
#         number_of_pass = np.mean(lf*seat_cap)
#         mean_per_air.append(number_of_pass)
#     period_mean = np.mean(np.array(mean_per_air))
#     plt.plot(unique_aircraft_types, mean_per_air, 'o', label=period_str)
#     plt.plot(unique_aircraft_types, np.linspace(period_mean, period_mean, len(mean_per_air)), alpha=0.5, label=period_str)

# plt.xlabel('Aircraft types')
# plt.xticks(rotation=90)
# plt.ylabel('Mean number of passengers')
# plt.legend()

# plt.savefig('MeanPerAircraft.pdf')
# plt.show()


# march2022_path = 'Future Schedule 20220301-20220331.xlsx'
# march2022 = pd.read_excel(march2022_path)

# destination_data = np.asarray(
#     raw_data[throw_away_due_to_covid:].Destination.unique())
# destination_march = np.asarray(march2022.Destination.unique())

# top_80_pc_data = transformer.select_top_features(data, 'Destination', 80)
# top_80_pc_march = transformer.select_top_features(march2022, 'Destination', 80)


# non_unique = []
# for destination in destination_march:
#     if destination not in destination_data:
#         non_unique.append(destination)


# cat_feat = ['Airline', 'AircraftType']
# cat_dict = {}
# for cat in cat_feat:
#     cat_dict[cat] = transformer.select_top_features(data, cat, 85)
#     print(len(cat_dict[cat]))

# data.loc[~data.Airline.isin(cat_dict['Airline'])] = 'Other'
